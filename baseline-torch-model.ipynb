{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28053f5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:24.221768Z",
     "iopub.status.busy": "2025-03-06T20:30:24.221507Z",
     "iopub.status.idle": "2025-03-06T20:30:34.825902Z",
     "shell.execute_reply": "2025-03-06T20:30:34.825223Z"
    },
    "papermill": {
     "duration": 10.610302,
     "end_time": "2025-03-06T20:30:34.827539",
     "exception": false,
     "start_time": "2025-03-06T20:30:24.217237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9987413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:34.836429Z",
     "iopub.status.busy": "2025-03-06T20:30:34.836032Z",
     "iopub.status.idle": "2025-03-06T20:30:34.929914Z",
     "shell.execute_reply": "2025-03-06T20:30:34.929036Z"
    },
    "papermill": {
     "duration": 0.099443,
     "end_time": "2025-03-06T20:30:34.931284",
     "exception": false,
     "start_time": "2025-03-06T20:30:34.831841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT = \"/kaggle/input/finalized-astrovision-data\"\n",
    "\n",
    "SEED = 3126\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "LEARNING_RATE = .001\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TARGET_MAP = {\n",
    "    \"Ellipticals\":0,\n",
    "    \"Irregulars\":1,\n",
    "    \"Lenticulars\":2,\n",
    "    \"Spirals\":3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4842d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:34.938405Z",
     "iopub.status.busy": "2025-03-06T20:30:34.938124Z",
     "iopub.status.idle": "2025-03-06T20:30:34.949159Z",
     "shell.execute_reply": "2025-03-06T20:30:34.948420Z"
    },
    "papermill": {
     "duration": 0.015949,
     "end_time": "2025-03-06T20:30:34.950427",
     "exception": false,
     "start_time": "2025-03-06T20:30:34.934478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)               # Python's built-in random module\n",
    "    np.random.seed(seed)            # NumPy\n",
    "    torch.manual_seed(seed)         # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)    # PyTorch GPU\n",
    "    torch.cuda.manual_seed_all(seed) # For all GPUs (if applicable)\n",
    "\n",
    "    # Ensures deterministic behavior in some operations\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "    \n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612fa13f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:34.956999Z",
     "iopub.status.busy": "2025-03-06T20:30:34.956769Z",
     "iopub.status.idle": "2025-03-06T20:30:34.961406Z",
     "shell.execute_reply": "2025-03-06T20:30:34.960615Z"
    },
    "papermill": {
     "duration": 0.009307,
     "end_time": "2025-03-06T20:30:34.962715",
     "exception": false,
     "start_time": "2025-03-06T20:30:34.953408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "means = [0.1431, 0.1285, 0.1565]\n",
    "stds = [0.1314, 0.1237, 0.1443]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(.5),\n",
    "    transforms.RandomVerticalFlip(.5),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.Normalize(mean=means, std=stds)\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=means, std=stds)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c746c0bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:34.969270Z",
     "iopub.status.busy": "2025-03-06T20:30:34.969024Z",
     "iopub.status.idle": "2025-03-06T20:30:34.974096Z",
     "shell.execute_reply": "2025-03-06T20:30:34.973361Z"
    },
    "papermill": {
     "duration": 0.0097,
     "end_time": "2025-03-06T20:30:34.975383",
     "exception": false,
     "start_time": "2025-03-06T20:30:34.965683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GalaxyData(Dataset):\n",
    "    def __init__(self, ROOT, transforms=None):\n",
    "        self.ROOT = ROOT\n",
    "        self.transforms = transforms\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "\n",
    "        for category in TARGET_MAP.keys():\n",
    "            category_path = os.path.join(ROOT, category)\n",
    "            img_files = os.listdir(category_path)\n",
    "            for img_file in img_files:\n",
    "                img_path = os.path.join(category_path, img_file)\n",
    "                self.imgs.append(img_path)\n",
    "                self.labels.append(TARGET_MAP[category])\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img   = Image.open(self.imgs[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a8bddec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:34.981917Z",
     "iopub.status.busy": "2025-03-06T20:30:34.981698Z",
     "iopub.status.idle": "2025-03-06T20:30:35.094748Z",
     "shell.execute_reply": "2025-03-06T20:30:35.093961Z"
    },
    "papermill": {
     "duration": 0.117656,
     "end_time": "2025-03-06T20:30:35.096022",
     "exception": false,
     "start_time": "2025-03-06T20:30:34.978366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = GalaxyData(ROOT, None)\n",
    "\n",
    "test_fold, train_fold = train_test_split(\n",
    "    range(len(dataset)),\n",
    "    test_size=.8,\n",
    "    shuffle=True,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "## Separates train data\n",
    "train_dataset = GalaxyData(ROOT, train_transforms)\n",
    "train_dataset = Subset(train_dataset, train_fold)\n",
    "## Separates validation data\n",
    "val_dataset   = GalaxyData(ROOT, test_transforms)\n",
    "val_dataset   = Subset(val_dataset, test_fold)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          num_workers=4, worker_init_fn=worker_init_fn)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                          num_workers=4, worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c6c681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:35.102672Z",
     "iopub.status.busy": "2025-03-06T20:30:35.102434Z",
     "iopub.status.idle": "2025-03-06T20:30:35.107212Z",
     "shell.execute_reply": "2025-03-06T20:30:35.106431Z"
    },
    "papermill": {
     "duration": 0.009356,
     "end_time": "2025-03-06T20:30:35.108404",
     "exception": false,
     "start_time": "2025-03-06T20:30:35.099048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, early_stopping_rounds=5, min_loss_change=0.001, verbose=False):\n",
    "        \"\"\"\n",
    "        An implementation of early stopping to restrain overfitting in the model. \n",
    "        \n",
    "            early_stopping_rounds (int): Number of epochs to wait after last improvement.\n",
    "            min_score_change (float): Minimum change in monitored metric to qualify as improvement.\n",
    "            verbose (bool): Whether to print early stopping messages.\n",
    "        \"\"\"\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.min_loss_change = min_loss_change\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        ## Improvement in loss has occurred; resets counter and saves current model\n",
    "        if val_loss < self.best_loss - self.min_loss_change:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')  \n",
    "        ## No improvement in loss occurred; increases counter\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: [{self.counter}/{self.early_stopping_rounds}]\\n\")\n",
    "            if self.counter >= self.early_stopping_rounds:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70630237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:35.114807Z",
     "iopub.status.busy": "2025-03-06T20:30:35.114587Z",
     "iopub.status.idle": "2025-03-06T20:30:35.119045Z",
     "shell.execute_reply": "2025-03-06T20:30:35.118275Z"
    },
    "papermill": {
     "duration": 0.008941,
     "end_time": "2025-03-06T20:30:35.120249",
     "exception": false,
     "start_time": "2025-03-06T20:30:35.111308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, loss_fn, val_loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total_samples = 0.0, 0.0, 0.0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for imgs,labels in val_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "    \n",
    "            y_preds = model(imgs)\n",
    "            loss = loss_fn(y_preds, labels.long())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            total_samples += labels.size(0)\n",
    "            preds = torch.argmax(y_preds, dim=1)\n",
    "            correct += torch.sum(preds==labels).item()\n",
    "\n",
    "        accuracy = correct/total_samples\n",
    "        avg_loss = total_loss/len(val_loader)\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc6b07e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:35.126779Z",
     "iopub.status.busy": "2025-03-06T20:30:35.126583Z",
     "iopub.status.idle": "2025-03-06T20:30:35.131023Z",
     "shell.execute_reply": "2025-03-06T20:30:35.130410Z"
    },
    "papermill": {
     "duration": 0.008903,
     "end_time": "2025-03-06T20:30:35.132099",
     "exception": false,
     "start_time": "2025-03-06T20:30:35.123196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader):\n",
    "    model.train()\n",
    "    total_loss, correct, total_samples = 0.0, 0.0, 0.0\n",
    "        \n",
    "    for imgs,labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        ## Predicts logit\n",
    "        y_preds = model(imgs)\n",
    "        ## Computes loss\n",
    "        loss = loss_fn(y_preds, labels.long())\n",
    "        total_loss += loss.item()\n",
    "        ## Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_samples += labels.size(0)\n",
    "        preds = torch.argmax(y_preds, dim=1)\n",
    "        correct += torch.sum(preds==labels).item()\n",
    "        \n",
    "    accuracy = correct/total_samples\n",
    "    avg_loss = total_loss/len(train_loader)\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d5abac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:35.138684Z",
     "iopub.status.busy": "2025-03-06T20:30:35.138461Z",
     "iopub.status.idle": "2025-03-06T20:30:35.143750Z",
     "shell.execute_reply": "2025-03-06T20:30:35.143109Z"
    },
    "papermill": {
     "duration": 0.009858,
     "end_time": "2025-03-06T20:30:35.144821",
     "exception": false,
     "start_time": "2025-03-06T20:30:35.134963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_validate_loop(epochs, model, optimizer, loss_fn, \n",
    "                        train_loader, val_loader, \n",
    "                        early_stopping_rounds=5, lr_schedule=None):\n",
    "    train_accuracies = []\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    val_losses = []\n",
    "\n",
    "    history = {}\n",
    "    early_stopping = EarlyStopping(early_stopping_rounds=early_stopping_rounds,\n",
    "                                   min_loss_change=0.001,\n",
    "                                   verbose=True)\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        ### TRAINING PHASE\n",
    "        train_accuracy, train_loss = train(model, optimizer, loss_fn, train_loader)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Training Epoch [{epoch}/{epochs}] - Accuracy: {train_accuracy:.4f} | Loss: {train_loss:.4f}\")\n",
    "\n",
    "        ### VALIDATION PHASE\n",
    "        val_accuracy, val_loss = validate(model, loss_fn, val_loader)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Validation - Accuracy: {val_accuracy:.4f} | Loss: {val_loss:.4f}\\n\")\n",
    "\n",
    "        ### EARLY STOPPING CHECK\n",
    "        early_stopping(model, val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "        ### LR SCHEDULER STEPPING\n",
    "        if lr_schedule is not None: lr_schedule.step()\n",
    "            \n",
    "    history[\"train_accuracies\"] = train_accuracies\n",
    "    history[\"val_accuracies\"]   = val_accuracies\n",
    "    history[\"train_losses\"] = train_losses\n",
    "    history[\"val_losses\"]   = val_losses\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89aa2cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:35.151208Z",
     "iopub.status.busy": "2025-03-06T20:30:35.151000Z",
     "iopub.status.idle": "2025-03-06T20:30:35.158565Z",
     "shell.execute_reply": "2025-03-06T20:30:35.157902Z"
    },
    "papermill": {
     "duration": 0.012013,
     "end_time": "2025-03-06T20:30:35.159744",
     "exception": false,
     "start_time": "2025-03-06T20:30:35.147731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CoordinateAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(CoordinateAttention, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.reduction   = reduction\n",
    "        \n",
    "        # avg_pool_x: (B, C, H, 1)\n",
    "        # avg_pool_y: (B, C, 1, W)\n",
    "        self.avg_pool_x = nn.AdaptiveAvgPool2d((None, 1))\n",
    "        self.avg_pool_y = nn.AdaptiveAvgPool2d((1, None))\n",
    "        # Downsampling\n",
    "        self.conv1  = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1, bias=False)\n",
    "        self.bn     = nn.BatchNorm2d(in_channels // reduction)\n",
    "        # Upsampling to size of input\n",
    "        self.conv_x = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1, bias=True)\n",
    "        self.conv_y = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1, bias=True)\n",
    "        self.init_modules_weights()\n",
    "        \n",
    "    def init_modules_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, .25) \n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.ones_(module.weight)\n",
    "                nn.init.constant_(module.bias, 0.25)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x_avg = self.avg_pool_x(x)  # (B, C, H, 1)\n",
    "        y_avg = self.avg_pool_y(x).permute(0, 1, 3, 2)  # (B, C, 1, W) -> (B, C, W, 1)\n",
    "        \n",
    "        concat    = torch.cat([x_avg, y_avg], dim=2)\n",
    "        attention = F.relu(self.bn(self.conv1(concat)))\n",
    "        # Split into spatial attentions\n",
    "        attention_x, attention_y = torch.split(attention, [H, W], dim=2)\n",
    "        attention_x = torch.sigmoid(self.conv_x(attention_x))\n",
    "        attention_y = torch.sigmoid(self.conv_y(attention_y))\n",
    "        # Reshape attention_y to match the original input dimensions\n",
    "        attention_y = attention_y.permute(0, 1, 3, 2)  # (B, C, W, 1) -> (B, C, 1, W)\n",
    "        \n",
    "        return x * attention_x * attention_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e43a2cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:35.166041Z",
     "iopub.status.busy": "2025-03-06T20:30:35.165846Z",
     "iopub.status.idle": "2025-03-06T20:30:35.173039Z",
     "shell.execute_reply": "2025-03-06T20:30:35.172410Z"
    },
    "papermill": {
     "duration": 0.011772,
     "end_time": "2025-03-06T20:30:35.174326",
     "exception": false,
     "start_time": "2025-03-06T20:30:35.162554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MobileNetResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, \n",
    "                 expansion_factor=3,\n",
    "                 downsample=False, \n",
    "                 use_attention=True, \n",
    "                 reduction=16\n",
    "                ):\n",
    "        super(MobileNetResBlock, self).__init__()\n",
    "        stride = 2 if downsample else 1\n",
    "        expanded_channels = out_channels * expansion_factor\n",
    "        \n",
    "        ## Implements attention mechanism\n",
    "        self.attention1 = nn.Sequential()\n",
    "        self.attention2 = nn.Sequential()\n",
    "        self.attention3 = nn.Sequential()\n",
    "        if use_attention:\n",
    "            self.attention1 = CoordinateAttention(expanded_channels, reduction)\n",
    "            self.attention2 = CoordinateAttention(expanded_channels, reduction)\n",
    "            self.attention3 = CoordinateAttention(out_channels, reduction)\n",
    "        ## Inverted Bottleneck Structure\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, expanded_channels, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(expanded_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            self.attention1,\n",
    "            nn.Conv2d(expanded_channels, expanded_channels, kernel_size=3, padding=1, bias=False, groups=expanded_channels),\n",
    "            nn.BatchNorm2d(expanded_channels),\n",
    "            self.attention2,\n",
    "            nn.Conv2d(expanded_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        ## Projection process matches dimensions of identity to new features\n",
    "        self.projection = nn.Sequential()\n",
    "        if (downsample) or (in_channels!=out_channels):\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )    \n",
    "        self.init_modules_weights()\n",
    "        \n",
    "    def init_modules_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0.25) \n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.ones_(module.weight)\n",
    "                nn.init.constant_(module.bias, 0.25)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        identity = self.projection(x)\n",
    "        x = self.features(x)\n",
    "        return F.relu(self.attention3(x + identity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800c5544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:35.180885Z",
     "iopub.status.busy": "2025-03-06T20:30:35.180687Z",
     "iopub.status.idle": "2025-03-06T20:30:35.190468Z",
     "shell.execute_reply": "2025-03-06T20:30:35.189651Z"
    },
    "papermill": {
     "duration": 0.014522,
     "end_time": "2025-03-06T20:30:35.191720",
     "exception": false,
     "start_time": "2025-03-06T20:30:35.177198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomMobileNetV3(nn.Module):\n",
    "    def __init__(self,\n",
    "                 expansion_factor=3,\n",
    "                 res_out_channels=[112, 160, 256, 480], \n",
    "                 blocks_per_layer=[2, 3, 3, 2],\n",
    "                 res_attention=[True, True, True, True],\n",
    "                 reduction=16\n",
    "                ):\n",
    "        super(CustomMobileNetV3, self).__init__()\n",
    "        self.res_in_channels = 80\n",
    "        \n",
    "        self.init_conv = nn.Sequential(\n",
    "            # 3x224x224 -> 64x112x112\n",
    "            MobileNetResBlock(3, 64, expansion_factor, downsample=True, use_attention=True, reduction=reduction),\n",
    "            # 64x112x112 -> 64x112x112\n",
    "            MobileNetResBlock(64, 64, expansion_factor, downsample=False, use_attention=False),\n",
    "            # 64x112x112 -> 80x56x56\n",
    "            MobileNetResBlock(64, 80, expansion_factor, downsample=True, use_attention=True, reduction=reduction),\n",
    "            # 80x56x56 -> 80x56x56\n",
    "            MobileNetResBlock(80, 80, expansion_factor, downsample=False, use_attention=False),\n",
    "        )\n",
    "\n",
    "         # 80x56x56 -> C1x56x56\n",
    "        self.res_layer1 = self.make_res_layer(res_out_channels[0], blocks_per_layer[0], expansion_factor, False, res_attention[0], reduction)\n",
    "        # C1x56x56 -> C2x28x28\n",
    "        self.res_layer2 = self.make_res_layer(res_out_channels[1], blocks_per_layer[1], expansion_factor, True, res_attention[1], reduction)\n",
    "        # C2x28x28 -> C3x14x14\n",
    "        self.res_layer3 = self.make_res_layer(res_out_channels[2], blocks_per_layer[2], expansion_factor, True, res_attention[2], reduction)\n",
    "        # C3x14x14 -> C4x7x7\n",
    "        self.res_layer4 = self.make_res_layer(res_out_channels[3], blocks_per_layer[3], expansion_factor, True, res_attention[3], reduction)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(res_out_channels[-1], 128, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 32, bias=False),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 4, bias=True)\n",
    "        )\n",
    "        self.init_modules_weights()\n",
    "\n",
    "    def make_res_layer(self, out_channels, blocks, expansion_factor, downsample=False, use_attention=True, reduction=16):\n",
    "        ## Initializes first block in layer\n",
    "        layers = [MobileNetResBlock(self.res_in_channels, out_channels, expansion_factor, downsample, use_attention, reduction)]\n",
    "        self.res_in_channels = out_channels\n",
    "        ## Attaches remaining blocks to layer with NO DOWNSAMPLING\n",
    "        for _ in range(blocks-1):\n",
    "            layers.append(MobileNetResBlock(out_channels, out_channels, expansion_factor, use_attention=use_attention, reduction=reduction))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def init_modules_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0.25) \n",
    "            elif isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):\n",
    "                nn.init.ones_(module.weight)\n",
    "                nn.init.constant_(module.bias, 0.25)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.init_conv(x)\n",
    "        x = self.res_layer1(x)\n",
    "        x = self.res_layer2(x)\n",
    "        x = self.res_layer3(x)\n",
    "        x = self.res_layer4(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4526dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:30:35.198227Z",
     "iopub.status.busy": "2025-03-06T20:30:35.197947Z",
     "iopub.status.idle": "2025-03-06T21:35:28.533100Z",
     "shell.execute_reply": "2025-03-06T21:35:28.532066Z"
    },
    "papermill": {
     "duration": 3893.339893,
     "end_time": "2025-03-06T21:35:28.534495",
     "exception": false,
     "start_time": "2025-03-06T20:30:35.194602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/100] - Accuracy: 0.5713 | Loss: 0.9823\n",
      "Validation - Accuracy: 0.6384 | Loss: 0.8732\n",
      "\n",
      "Training Epoch [2/100] - Accuracy: 0.6403 | Loss: 0.8284\n",
      "Validation - Accuracy: 0.6865 | Loss: 0.8132\n",
      "\n",
      "Training Epoch [3/100] - Accuracy: 0.6754 | Loss: 0.7512\n",
      "Validation - Accuracy: 0.7256 | Loss: 0.6569\n",
      "\n",
      "Training Epoch [4/100] - Accuracy: 0.7069 | Loss: 0.6709\n",
      "Validation - Accuracy: 0.7581 | Loss: 0.6521\n",
      "\n",
      "Training Epoch [5/100] - Accuracy: 0.7315 | Loss: 0.6327\n",
      "Validation - Accuracy: 0.7117 | Loss: 0.6639\n",
      "\n",
      "EarlyStopping counter: [1/10]\n",
      "\n",
      "Training Epoch [6/100] - Accuracy: 0.7340 | Loss: 0.6041\n",
      "Validation - Accuracy: 0.7671 | Loss: 0.5812\n",
      "\n",
      "Training Epoch [7/100] - Accuracy: 0.7590 | Loss: 0.5571\n",
      "Validation - Accuracy: 0.7818 | Loss: 0.5119\n",
      "\n",
      "Training Epoch [8/100] - Accuracy: 0.7659 | Loss: 0.5455\n",
      "Validation - Accuracy: 0.7679 | Loss: 0.5288\n",
      "\n",
      "EarlyStopping counter: [1/10]\n",
      "\n",
      "Training Epoch [9/100] - Accuracy: 0.7737 | Loss: 0.5278\n",
      "Validation - Accuracy: 0.7011 | Loss: 0.6961\n",
      "\n",
      "EarlyStopping counter: [2/10]\n",
      "\n",
      "Training Epoch [10/100] - Accuracy: 0.7747 | Loss: 0.5073\n",
      "Validation - Accuracy: 0.7044 | Loss: 0.8157\n",
      "\n",
      "EarlyStopping counter: [3/10]\n",
      "\n",
      "Training Epoch [11/100] - Accuracy: 0.7853 | Loss: 0.4954\n",
      "Validation - Accuracy: 0.7435 | Loss: 0.5424\n",
      "\n",
      "EarlyStopping counter: [4/10]\n",
      "\n",
      "Training Epoch [12/100] - Accuracy: 0.7861 | Loss: 0.4918\n",
      "Validation - Accuracy: 0.8005 | Loss: 0.4584\n",
      "\n",
      "Training Epoch [13/100] - Accuracy: 0.7906 | Loss: 0.4754\n",
      "Validation - Accuracy: 0.7875 | Loss: 0.4984\n",
      "\n",
      "EarlyStopping counter: [1/10]\n",
      "\n",
      "Training Epoch [14/100] - Accuracy: 0.8038 | Loss: 0.4598\n",
      "Validation - Accuracy: 0.8339 | Loss: 0.4061\n",
      "\n",
      "Training Epoch [15/100] - Accuracy: 0.7944 | Loss: 0.4893\n",
      "Validation - Accuracy: 0.8029 | Loss: 0.4510\n",
      "\n",
      "EarlyStopping counter: [1/10]\n",
      "\n",
      "Training Epoch [16/100] - Accuracy: 0.8038 | Loss: 0.4552\n",
      "Validation - Accuracy: 0.7329 | Loss: 0.6803\n",
      "\n",
      "EarlyStopping counter: [2/10]\n",
      "\n",
      "Training Epoch [17/100] - Accuracy: 0.8099 | Loss: 0.4522\n",
      "Validation - Accuracy: 0.7826 | Loss: 0.5580\n",
      "\n",
      "EarlyStopping counter: [3/10]\n",
      "\n",
      "Training Epoch [18/100] - Accuracy: 0.8101 | Loss: 0.4237\n",
      "Validation - Accuracy: 0.7191 | Loss: 0.6680\n",
      "\n",
      "EarlyStopping counter: [4/10]\n",
      "\n",
      "Training Epoch [19/100] - Accuracy: 0.8142 | Loss: 0.4401\n",
      "Validation - Accuracy: 0.7630 | Loss: 0.5980\n",
      "\n",
      "EarlyStopping counter: [5/10]\n",
      "\n",
      "Training Epoch [20/100] - Accuracy: 0.8174 | Loss: 0.4143\n",
      "Validation - Accuracy: 0.7940 | Loss: 0.5089\n",
      "\n",
      "EarlyStopping counter: [6/10]\n",
      "\n",
      "Training Epoch [21/100] - Accuracy: 0.8307 | Loss: 0.4049\n",
      "Validation - Accuracy: 0.7866 | Loss: 0.5389\n",
      "\n",
      "EarlyStopping counter: [7/10]\n",
      "\n",
      "Training Epoch [22/100] - Accuracy: 0.8221 | Loss: 0.4048\n",
      "Validation - Accuracy: 0.7899 | Loss: 0.4989\n",
      "\n",
      "EarlyStopping counter: [8/10]\n",
      "\n",
      "Training Epoch [23/100] - Accuracy: 0.8402 | Loss: 0.3820\n",
      "Validation - Accuracy: 0.7549 | Loss: 0.6423\n",
      "\n",
      "EarlyStopping counter: [9/10]\n",
      "\n",
      "Training Epoch [24/100] - Accuracy: 0.8343 | Loss: 0.3850\n",
      "Validation - Accuracy: 0.7386 | Loss: 0.6366\n",
      "\n",
      "EarlyStopping counter: [10/10]\n",
      "\n",
      "Early stopping triggered at epoch 24.\n"
     ]
    }
   ],
   "source": [
    "model = CustomMobileNetV3().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "history = train_validate_loop(\n",
    "    EPOCHS, \n",
    "    model,\n",
    "    optimizer, \n",
    "    loss_fn, \n",
    "    train_loader, \n",
    "    val_loader,\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6807513,
     "sourceId": 10945047,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3909.554522,
   "end_time": "2025-03-06T21:35:30.985359",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-06T20:30:21.430837",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
