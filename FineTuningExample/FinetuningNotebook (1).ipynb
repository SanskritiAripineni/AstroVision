{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This is an example notebook on how to use Optuna for finetuning"
      ],
      "metadata": {
        "id": "e_ybTdW7d_HA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zC1Kyh9FYcXi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "9uH0MDJjY2vT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sea\n",
        "import optuna\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, AdamW\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "iL7964-IYiy4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WIDTH, HEIGHT = 224, 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "DATA_PATH = '/content/drive/MyDrive/AstroVisionData/spaceImages'\n",
        "\n",
        "#data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "0-k6x1xeYvhm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed_value=3126):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "\n",
        "set_seed()"
      ],
      "metadata": {
        "id": "tgbfi9hGj6n8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_train_val_generators(batch_size):\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      DATA_PATH,\n",
        "      target_size=(WIDTH, HEIGHT),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical',\n",
        "      subset='training')\n",
        "\n",
        "  validation_generator = train_datagen.flow_from_directory(\n",
        "    DATA_PATH,\n",
        "    target_size=(WIDTH, HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        "  )\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "ElOYiJCJbr8B"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def base_model_objective(trial):\n",
        "  ## Define distributions of hyperparams\n",
        "  ## log is used for ensuring faster convergence for skewed distributions\n",
        "  batch_size_    = trial.suggest_int(\"batch_size\", 8, 64)\n",
        "  learning_rate_ = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
        "  dense_input_   = trial.suggest_int(\"dense_input\", 128, 4096, step=128)\n",
        "  activation_    = trial.suggest_categorical(\"activation\", [\"relu\", \"leakyrelu\", \"swish\"])\n",
        "  optimizer_     = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\"])\n",
        "  weight_decay_  = trial.suggest_float(\"weight_decay\", 1e-8, 1e-2, log=True)\n",
        "  beta1_         = trial.suggest_float(\"beta1\", .885, .999) # momentum\n",
        "  beta2_         = trial.suggest_float(\"beta2\", .885, .999) # momentum\n",
        "  if activation_==\"leakyrelu\":\n",
        "    leakyrelu_alpha_  = trial.suggest_float(\"leakyrelu_alpha\", .05, .5, log=True)\n",
        "\n",
        "  ## Gets model\n",
        "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "  ## Allocates the proper activation function as selected by the algorithm\n",
        "  if activation_ == \"leakyrelu\":\n",
        "    x = Dense(dense_input_)(x)\n",
        "    x = LeakyReLU(alpha=leakyrelu_alpha_)(x)\n",
        "  elif activation_ == \"swish\":\n",
        "        x = Dense(dense_input_, activation=tf.nn.swish)(x)\n",
        "  else:\n",
        "    x = Dense(dense_input_, activation=activation_)(x)\n",
        "  predictions = Dense(6, activation='softmax')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  ## Allocates the proper optimizer\n",
        "  if optimizer_==\"Adam\":\n",
        "    optimizer_ = Adam(learning_rate_)\n",
        "  else:\n",
        "    optimizer_ = AdamW(learning_rate_, weight_decay_, beta1_, beta2_)\n",
        "\n",
        "  ## Prepares train and validation generator from algorithm's batch size\n",
        "  train_generator, validation_generator = prepare_train_val_generators(batch_size_)\n",
        "\n",
        "  ## Trains model for epochs times\n",
        "  epochs = 5\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "  model.compile(optimizer=optimizer_, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "\n",
        "  ## Extracts validation accuracy for Optuna to check how good its chosen hyperparams are\n",
        "  val_acc = history.history[\"val_accuracy\"][-1]\n",
        "  return val_acc"
      ],
      "metadata": {
        "id": "SmpBI935YylO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Objective is to maximize accuracy!\n",
        "study = optuna.create_study(study_name=\"baseline_params_search\", direction=\"maximize\")\n",
        "## Runs the search for hyperparams\n",
        "study.optimize(base_model_objective, n_trials=100)"
      ],
      "metadata": {
        "id": "agKCCkwtZeB_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best parameters:\", study.best_params)\n",
        "print(\"Best validation accuracy:\", study.best_value)"
      ],
      "metadata": {
        "id": "PtHIoeF0dlf-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}